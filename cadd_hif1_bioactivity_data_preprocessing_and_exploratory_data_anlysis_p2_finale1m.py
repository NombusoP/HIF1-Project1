# -*- coding: utf-8 -*-
"""CADD_hif1_bioactivity_data_preprocessing_and_Exploratory_data_Anlysis_P2_finale1m.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/NombusoP/COMPUTATIONAL-DRUG-DISCOVERY/blob/main/CADD_hif1_bioactivity_data_preprocessing_and_Exploratory_data_Anlysis_P2_finale1m.ipynb

COMPUTATIONAL DRUG DISCOVERY P2


Exploratory data analysis

Import Libraries
"""

!pip install chembl_webresource_client

!pip install rdkit

import math
from pathlib import Path
from zipfile import ZipFile
from tempfile import TemporaryDirectory

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
from rdkit.Chem import PandasTools
from chembl_webresource_client.new_client import new_client
from tqdm.auto import tqdm

from chembl_webresource_client.new_client import new_client
from rdkit import Chem
from rdkit.Chem import Descriptors, Lipinski

targets_api=new_client.target
compounds_api=new_client.molecule
bioactivities_api=new_client.activity

"""
get target data from ChEMBL,
get UniProt ID of the target"""

uniprot_id='Q16665'

from IPython.display import Image
print('PDB:1H2M','\n','HIF-1 in complex with HIF-1 alpha fragment peptide','\n','HIF-1 alpha in cyan colour')
Image(filename='1h2m.png',width=400,height=250)

targets = targets_api.get(target_components__accession=uniprot_id).only(
    "target_chembl_id", "organism", "pref_name", "target_type"
)
print(f'The type of the targets is "{type(targets)}"')

"""search and download Target protein"""

target=new_client.target
target_query=target.search(' hypoxia inducible factor receptor')
targets=pd.DataFrame.from_dict(target_query)
targets

"""Select the target (target ChEMBL ID)"""

selected_target=targets.target_chembl_id[1]
print('Target ChEMBL ID is :',selected_target)

""" information on the selected target"""

target=targets.iloc[1]
target

"""save the selcted ChEMBL ID"""

chembl_id=target.target_chembl_id
print('the selected ChEMBL ID is:',chembl_id)

"""OBTAIN BIOACTIVITY DATA( which is reported as IC50 values in nM)

-get bioactivity data for the target (Hypoxia-inducible factor 1 alpha)

-obtain bioactity data including the following:

-human proteins

-bioactivity type IC50

exact measurement(relation'=')

binding assays (assay type 'B')
"""

bioactivities = bioactivities_api.filter(
    target_chembl_id=chembl_id, type="IC50", relation="=", assay_type="B",
).only(

    "activity_id",
    "assay_chembl_id",
    "assay_description",
    "assay_type",
    "molecule_chembl_id",
    "type",
    "standard_units",
    "relation",
    "standard_value",
    "target_chembl_id",
    "target_organism",
)

print(f"Length and type of bioactivities object: {len(bioactivities[0])}, {type(bioactivities[0])}")
bioactivities[0]

"""bioactivity data of the above columns contain the following information

Download bioactivty data from ChEMBL in a pandas DF format
"""

bioactivities_df = pd.DataFrame.from_dict(bioactivities)
print(f"DataFrame shape: {bioactivities_df.shape}")
bioactivities_df.head()

"""columns , standard_units and units have the same entry

-standard_value/value columns also have the same entry,

-in this case ChEMBL standardised  column will be used , thus dropping values and units columns

checking  'units' column whether the value measurements in this column are the similar(uniform)
"""

bioactivities_df['units'].unique()

bioactivities_df.shape

"""dropping 'values' and 'units' columns"""

bioactivities_df.drop(["units", "value"], axis=1, inplace=True)
bioactivities_df.head()

"""also check the column 'type' which holds the IC50 data,

-check if  this bioactivity data is ONLY recorded as IC50
"""

bioactivities_df['type'].unique()

"""PREPROCESS AND FILTER BIOACTIVITY DATA

1.convert datatype for  standard_values column from object dtype  to float dtype

-standard_value contains standardised(IC50) values.

-to use the values for subsequent calculations and analysis ,

convert values to float dtype
"""

bioactivities_df.dtypes

bioactivities_df = bioactivities_df.astype({"standard_value": "float64"})
bioactivities_df.dtypes

"""check whether the standard_value dtype is now a float"""

bioactivities_df['standard_value'].dtypes

"""columns information"""

bioactivities_df.columns

"""check and delete entries with missing values

-check all missing values reported as 'NA',  ' ', np.NaN, None

-can aslo use isnull () function to checking for any missing values

"""

missing_values=['NA','',np.NaN,None]
missing=bioactivities_df.isin(missing_values)
print(missing)

bioactivities_df.dropna(axis=0, how="any", inplace=True)
print(f"DataFrame shape: {bioactivities_df.shape}")

"""checking shape of DF, number of rows and columns"""

bioactivities_df.shape

number_rows,number_columns=bioactivities_df.shape
print('number of rows:',number_rows,'\n','number of columns:',number_columns)

"""create heatmap to check for missing data"""

sns.heatmap(bioactivities_df.isnull())

bioactivities_df.isnull().sum()

"""3. keep entries with standard_unit=='nM' unit measurement

"""

print(f"Units in downloaded data: {bioactivities_df['standard_units'].unique()}")
print(
    f"Number of non-nM entries:\
    {bioactivities_df[bioactivities_df['standard_units'] != 'nM'].shape[0]}"
)

"""check if the standard_units column has only nM entries,
-check DF shape i.e number of rows and columns
"""

bioactivities_df['standard_units'].unique()

bioactivities_df = bioactivities_df[bioactivities_df["standard_units"] == "nM"]
print(f"Units after filtering: {bioactivities_df['standard_units'].unique()}")

print(f"DataFrame shape: {bioactivities_df.shape}")

"""drop  duplicate entries

-keep first entries of the same molecule_chembl_id,

-check DF shape
"""

bioactivities_df.drop_duplicates("molecule_chembl_id", keep="first", inplace=True)
print(f"DataFrame shape: {bioactivities_df.shape}")

number_rows,number_columns=bioactivities_df.shape
print('number of rows:',number_rows,'\n','number of columns:',number_columns)

"""rename DF"""

hif_bioactivities_df2a=bioactivities_df
hif_bioactivities_df2a.head()

hif_bioactivities_df2a.head()

hif_bioactivities_df2a.shape

"""OBTAIN COMPOUND DATA



"""

compounds_provider = compounds_api.filter(
    molecule_chembl_id__in=list(bioactivities_df["molecule_chembl_id"])
).only("molecule_chembl_id", "molecule_structures")

"""Download compound data from ChEMBL"""

compounds = list(tqdm(compounds_provider))

compounds_df = pd.DataFrame.from_records(
    compounds,
)
print(f"DataFrame shape: {compounds_df.shape}")

compounds_df.head()

compounds_df.shape

"""Preprocessing  and filtering of the  compound data

-checking missing entries of compounds DF,


-remove missing entries

-delete duplicates

-obtain molcules with canonical smiles only
"""

#heatmap for checking missing entries
sns.heatmap(compounds_df.isnull())

"""1.remove missing entries"""

compounds_df.dropna(axis=0, how="any", inplace=True)
print(f"DataFrame shape: {compounds_df.shape}")

"""2. delete molecules with duplicate entries"""

compounds_df.drop_duplicates("molecule_chembl_id", keep="first", inplace=True)
print(f"DataFrame shape: {compounds_df.shape}")

"""3. obtain molecules with canonical smiles"""

compounds_df.iloc[0].molecule_structures.keys()

canonical_smiles = []

for i, compounds in compounds_df.iterrows():
    try:
        canonical_smiles.append(compounds["molecule_structures"]["canonical_smiles"])
    except KeyError:
        canonical_smiles.append(None)

compounds_df["smiles"] = canonical_smiles
compounds_df.drop("molecule_structures", axis=1, inplace=True)
print(f"DataFrame shape: {compounds_df.shape}")

"""compounds without canonical SMILES strings to be removed"""

compounds_df.dropna(axis=0, how="any", inplace=True)
print(f"DataFrame shape: {compounds_df.shape}")

"""recheck missing data in the compounds DF"""

compounds_df.isnull().sum()

"""Bioactivity data and Compound data summary"""

print(f"Bioactivities filtered: {hif_bioactivities_df2a.shape[0]}")
hif_bioactivities_df2a.columns

bioactivity_column_names=hif_bioactivities_df2a.columns
print('bioactivities column summary :',"\n",bioactivity_column_names)

print(f"Compounds filtered: {compounds_df.shape[0]}")
compounds_df.columns

compound_column_names=compounds_df.columns
print('compound column summary :','\n',compound_column_names)

"""merge  both bioactivity and compoud DF and rename DF"""

compounds_df.head(3)

hif_bioactivities_df2a.head(3)

"""merge data frames keeping selected parameters"""

output_df = pd.merge(
    hif_bioactivities_df2a[["molecule_chembl_id", "standard_value", "standard_units",]],
    compounds_df,
    on="molecule_chembl_id",
)

# Reset row indices
output_df.reset_index(drop=True, inplace=True)

print(f"Dataset with {output_df.shape[0]} entries.")

output_df.head()

"""rename data frame that has been merged



"""

hif_dfx=output_df
hif_dfx.head(3)

hif_dfx.shape

hif_dfx.rename(
    columns={'smiles':'canonical_smiles'},inplace=True
)

"""classifying and labelling compounds as ,
active, inactive  or intermediate
"""

bioactivity_class=[]
for i in hif_dfx.standard_value:
  if float (i) >=10000:
    bioactivity_class.append('inactive')
  elif float (i) <= 1000:
    bioactivity_class.append('active')
  else:
   bioactivity_class.append('intermediate')

"""iterate  molecule_chembl_id,   canonica_smiles,   standard_value to a list"""

#chembl_id
mol_cid= hif_dfx['molecule_chembl_id']
mol_cid=[]
for i in hif_dfx.molecule_chembl_id:
  mol_cid.append(i)

mol_cid

canonical_smiles=[]
for i in hif_dfx.canonical_smiles:
  canonical_smiles.append(i)

canonical_smiles

standard_value=[]
for i in hif_dfx.standard_value:
  standard_value.append(i)

standard_value

"""combine the list [mol_cid, canonical_smiles, bioactivity_class_standard_value] into DF"""

data_tuples=list(zip(mol_cid,canonical_smiles,bioactivity_class,standard_value))
dfx=pd.DataFrame(data_tuples,columns=['molecule_chembl_id','canonical_smiles','bioactivity_class','standard_value'])

dfx

"""Calculate the descriptors"""

#from: https://codeocean.com/explore/capsules?query=tag:data-curation

def lipinski(smiles, verbose=False):

    moldata= []
    for elem in smiles:
        mol=Chem.MolFromSmiles(elem)
        moldata.append(mol)

    baseData= np.arange(1,1)
    i=0
    for mol in moldata:

        desc_MolWt = Descriptors.MolWt(mol)
        desc_MolLogP = Descriptors.MolLogP(mol)
        desc_NumHDonors = Lipinski.NumHDonors(mol)
        desc_NumHAcceptors = Lipinski.NumHAcceptors(mol)

        row = np.array([desc_MolWt,
                        desc_MolLogP,
                        desc_NumHDonors,
                        desc_NumHAcceptors])

        if(i==0):
            baseData=row
        else:
            baseData=np.vstack([baseData, row])
        i=i+1

    columnNames=["MW","LogP","NumHDonors","NumHAcceptors"]
    descriptors = pd.DataFrame(data=baseData,columns=columnNames)

    return descriptors

df_lipinski =lipinski(dfx.canonical_smiles)
df_lipinski

df_combined=pd.concat([dfx,df_lipinski],axis=1)
df_combined

"""distribution of standard_value (IC50)"""

print('standard_value (IC50)distribution')
plt.style.use('dark_background')
plt.rcParams['figure.figsize']=(8,3)
df_combined['standard_value'].hist(bins=30)
plt.show()

""" IC50 to PIC50 Transformation:


-IC50 reported in standard_value column has uneven distribution data

-large values will be capped to 100 000 000 so that the large value do not become negative  after transformation

-standard_values are converted to negative logarithmic scale
"""

def capping_large_values (item):
  if item >100000000:
    return 100000000
  else:
      return item

df_combined['standard_value']=df_combined['standard_value'].apply(capping_large_values)

"""checking values that needed capping"""

len(df_combined.loc[df_combined['standard_value']==100000000]) #checking values that needed capping,none needed capping

def neg_log_transformation(item):
  item=item*(10**-9)
  return -np.log10(item)

df_combined['standard_value_transformed']=df_combined['standard_value'].apply(neg_log_transformation)

df_combined[df_combined['standard_value_transformed']<0]

plt.style.use('dark_background')
plt.rcParams['figure.figsize']=(8,3)
df_combined[['standard_value','standard_value_transformed']].hist(bins=30)
plt.show()

df_combined.head(5)

""" -function that converts IC50  to PIC50



"""

def convert_ic50_to_pic50(IC50_value):
  pic50_value=9 -math.log10(IC50_value)
  return pic50_value

convert_ic50_to_pic50(1)

convert_ic50_to_pic50(1000)

convert_ic50_to_pic50(10000)

convert_ic50_to_pic50(820)

convert_ic50_to_pic50(3400)

convert_ic50_to_pic50(11900)

"""rename columns:

-standard_value: IC50

-standard_vaue_transformed:pIC50
"""

df_combined.rename(
    columns ={'standard_value':'IC50','standard_value_transformed':'pIC50'},inplace=True
    )

df_combined

"""remove intermediate bioactivity class"""

df_final=df_combined[df_combined.bioactivity_class!='intermediate']
df_final

"""add rdkit column
-sort molecules by pIC50 values
"""

PandasTools.AddMoleculeColumnToFrame(df_final,smilesCol='canonical_smiles')

df_final



""" save bioactivity data to a CSV"""

df_final.to_csv('bioactivity_data.csv', index=False)

""" copy files to Google Drive."""

from google.colab import drive
drive.mount('/content/gdrive/', force_remount=True)

! mkdir "/content/gdrive/My Drive/Colab Notebooks/data126"

! cp bioactivity_data.csv "/content/gdrive/My Drive/Colab Notebooks/data"

"""  Description  of the data in the Bioactivity Data Frame"""

df_final.describe()

"""EXPLORATORY DATA ANLYSIS

Frequency plots for active and inactive bioactivity classes
"""

import seaborn as sns
sns.set(style='ticks')
import matplotlib.pyplot as plt

plt.figure(figsize=(5.5, 5.5))

sns.countplot(x='bioactivity_class', data=df_final, palette = ["goldenrod", "purple"], edgecolor='black',hue='bioactivity_class',legend=False)

plt.xlabel('Bioactivity class', fontsize=14, fontweight='bold')
plt.ylabel('Frequency', fontsize=14, fontweight='bold')
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.savefig('plot_bioactivity_class.pdf')

"""Scatter plot for Molecular Weight (MW) vs LogP"""

plt.figure(figsize=(5.5, 5.5))

sns.scatterplot(x='MW', y='LogP', data=df_final, hue='bioactivity_class', size='pIC50', edgecolor='black', alpha=0.7)

plt.xlabel('MW', fontsize=14, fontweight='bold')
plt.ylabel('LogP', fontsize=14, fontweight='bold')
plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)
plt.savefig('plot_MW_vs_LogP.pdf')

"""BOXPLOTS AND STATISTICAL ANALYSIS

STATISTICAL ANALYSIS

MannWhitney U-test
"""

def mannwhitney(descriptor, verbose=False):
  # https://machinelearningmastery.com/nonparametric-statistical-significance-tests-in-python/
  from numpy.random import seed
  from numpy.random import randn
  from scipy.stats import mannwhitneyu

# seed the random number generator
  seed(1)

# actives and inactives
  selection = [descriptor, 'bioactivity_class']
  df = df_final[selection]
  active = df[df.bioactivity_class == 'active']
  active = active[descriptor]

  selection = [descriptor, 'bioactivity_class']
  df = df_final[selection]
  inactive = df[df.bioactivity_class == 'inactive']
  inactive = inactive[descriptor]

# compare samples
  stat, p = mannwhitneyu(active, inactive)
  #print('Statistics=%.3f, p=%.3f' % (stat, p))

# interpret
  alpha = 0.05
  if p > alpha:
    interpretation = 'Same distribution (fail to reject H0)'
  else:
    interpretation = 'Different distribution (reject H0)'

  results = pd.DataFrame({'Descriptor':descriptor,
                          'Statistics':stat,
                          'p':p,
                          'alpha':alpha,
                          'Interpretation':interpretation}, index=[0])
  filename = 'mannwhitneyu_' + descriptor + '.csv'
  results.to_csv(filename)

  return results

"""BOXPLOTS

Molecular Weight(MW)
"""

plt.figure(figsize=(5.5, 5.5))

sns.boxplot(x = 'bioactivity_class', y = 'MW', data = df_final)

plt.xlabel('Bioactivity class', fontsize=14, fontweight='bold')
plt.ylabel('MW', fontsize=14, fontweight='bold')

plt.savefig('plot_MW.pdf')

mannwhitney('MW')

"""NumHDonors"""

plt.figure(figsize=(5.5, 5.5))

sns.boxplot(x = 'bioactivity_class', y = 'NumHDonors', data = df_final)

plt.xlabel('Bioactivity class', fontsize=14, fontweight='bold')
plt.ylabel('NumHDonors', fontsize=14, fontweight='bold')

plt.savefig('plot_NumHDonors.pdf')

mannwhitney('NumHDonors')

plt.figure(figsize=(5.5, 5.5))

sns.boxplot(x = 'bioactivity_class', y = 'NumHAcceptors', data = df_final)

plt.xlabel('Bioactivity class', fontsize=14, fontweight='bold')
plt.ylabel('NumHAcceptors', fontsize=14, fontweight='bold')

plt.savefig('plot_NumHAcceptors.pdf')

mannwhitney('NumHAcceptors')

"""LogP"""

plt.figure(figsize=(5.5, 5.5))

sns.boxplot(x = 'bioactivity_class', y = 'LogP', data = df_final)

plt.xlabel('Bioactivity class', fontsize=14, fontweight='bold')
plt.ylabel('LogP', fontsize=14, fontweight='bold')

plt.savefig('plot_LogP.pdf')

mannwhitney('LogP')

plt.figure(figsize=(5.5, 5.5))

sns.boxplot(x = 'bioactivity_class', y = 'pIC50', data = df_final)

plt.xlabel('Bioactivity class', fontsize=14, fontweight='bold')
plt.ylabel('pIC50 value', fontsize=14, fontweight='bold')

plt.savefig('plot_ic50.pdf')

mannwhitney('pIC50')

"""Summary

-bioactivity data of the target of interest (hypoxia inducible factor1 alpha) was collected

-data was preprocessed, filtered to obtain compounds   that measured IC50 bioactivity values

-bioactivity of compounds  was classified as either being, active, inactive or intermediate

-compounds with IC50  value of less than 1000nM =Active, ( pIC50 >6)

-compounds with IC50 value that is greater than 10 000 nM= Inactive,(pIC50<5)

-for further analysis  intermediate bioactivity class was dropped,

-compounds were finally classified as beiing active or inactive





MANNWHITNEY STATISTICAL RESULTS

-for pIC50 values , there was statistical significant difference between active and nonactive bioactivity compounds



-for Lipkinski descriptors(MW,NumHDonors), there was also statitical significant difference between active and inactive bioactivity compounds

-for LogP  and NumHAcceptors descriptors  there was no statisitical difference between active and inactive biaoctivity compounds

zip files
"""

! zip -r results3.zip . -i *.csv *.pdf